# -*- coding: utf-8 -*-
"""Trabajo Final Last Module.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NVAtonVmiI6ngE8BLtj80HjKg70RJCTh

# **TRABAJO FINAL**

# **1. Metodoligía**


Se utilizara una metodologia de aprendizaje supervisado siguiendo los siguientes pasos:

**i) Comprensión del Problema:** Entender el objetivo y requisitos del proyecto

**ii)Recopilación de Datos:** Obtener el conjunto de datos necesario.

**iii)Exploración y Preparación de Datos:** Limpiar y explorar los datos.

**iv)Análisis Exploratorio de Datos (EDA):** Identificar patrones y relaciones en los datos.

**v)Selección y Entrenamiento del Modelo:** Elegir un modelo adecuado y entrenarlo.

**vi)Evaluación del Modelo:** Evaluar el rendimiento del modelo con métricas apropiadas.

**vii)Ajuste y Optimización del Modelo:** Ajustar el modelo para mejorar su rendimiento.
"""



"""# **I. Comprensión del Problema**

El dataset esta compuesta por 4 columnas que pertenecen a las caracteristicas de la especie de la Flor Iris, la ultima columna es la especie de la Flor Iris.

***El objetivo*** es entrenar un módelo que aprenda la relación entre las caracteristicas y la especie, para poder predecir cual es la especie.

# **II. Recopilación de Datos:**
"""

import pandas as pd
from sklearn.model_selection import train_test_split,cross_val_score,KFold
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score,mean_squared_error,confusion_matrix
from sklearn import datasets
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

iris = datasets.load_iris()
df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)
df_iris["species"] = iris.target
df_iris["species_des"] = df_iris["species"].map({0: "iris-setosa", 1: "iris-versicolor", 2: "iris-virginica"})

df_iris.describe()

"""# **III. Exploración y Preparación de Datos:**"""

df_iris.head(10)

df_iris.isnull().sum()

df_iris.duplicated().sum()

df_iris[df_iris.duplicated()]

df_iris[(df_iris["species"] == 2) & (df_iris["sepal length (cm)"] == 5.8) & (df_iris['sepal width (cm)'] == 2.7)]

df_iris.drop_duplicates(inplace=True)

df_valor_atipico = pd.DataFrame()

for especie in df_iris['species_des'].unique():
    df_specie = df_iris[df_iris["species_des"] == especie]

    for colName in df_specie.select_dtypes(include="float64").columns:
        Q1, Q3 = np.percentile(df_specie[colName], [25, 75])
        IQR = Q3 - Q1
        lim_inf, lim_sup = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR

        df_valor_atipico_temp = df_specie.loc[(df_specie[colName] < lim_inf) | (df_specie[colName] > lim_sup),
                                 [colName, 'species_des']].copy()
        if not df_valor_atipico_temp.empty:
          df_valor_atipico_temp["Lim Inf"], df_valor_atipico_temp["Lim Sup"] = lim_inf, lim_sup

          print(f"""******************************************************************
          Valor Atipico de la especie {especie}, en su parametro {colName}""")
          display(df_valor_atipico_temp)
          print("******************************************************************")
          df_valor_atipico_temp = df_valor_atipico_temp.reset_index().rename(columns={'index': 'numIndex'})
          df_valor_atipico_temp.rename(columns={f'{colName}': 'col_error'}, inplace=True)
          df_valor_atipico = pd.concat([df_valor_atipico, df_valor_atipico_temp], ignore_index=True)

#Visualizacion de la informacion con datos atipicos
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

for i, feature in enumerate(df_iris.select_dtypes(include="float64").columns):
    row, col = i // 2, i % 2
    sns.boxplot(x="species_des", y=feature, data=df_iris, ax=axes[row, col])
    axes[row, col].set_title(f"Boxplot de {feature} por especie")

plt.tight_layout()
plt.show()

#df_iris = df_iris.drop(index=df_valor_atipico["numIndex"])

df_iris.info()

"""# **IV. ANALISIS EXPLORATORIO DE DATOS (EDA)**"""

# Visualización de la Distribución de los valores por caracteristica
fig, axes = plt.subplots(2, 2, figsize=(12, 8))

colsGrafico = df_iris.select_dtypes(include="float64").columns

for i, colName in enumerate(colsGrafico):
    row, col = i // 2, i % 2
    sns.histplot(df_iris[colName], bins=10, kde=True, ax=axes[row, col])
    xlabel = colName.replace("sepal","Sépalo").replace("petal","Pétalo").replace("length","(Largo)").replace("width","(Ancho)").replace(" (cm)","")
    axes[row, col].set_title(f"Distribución de {xlabel}")
    axes[row, col].set_ylabel("Frecuencia")
    axes[row, col].set_xlabel(xlabel)

plt.tight_layout()
plt.show()

# Visualización de la relación entre las variables para determinar la especie.

graficoPair = sns.pairplot(df_iris.select_dtypes(exclude="int64"), hue="species_des",diag_kind="kde") #diag_kind="hist"

nombres_columnas = ["Sépalo (Largo)", "Sépalo (Ancho)", "Pétalo (Largo)", "Pétalo (Ancho)"]

for i, ax in enumerate(graficoPair.axes[-1]):
    ax.set_xlabel(nombres_columnas[i])

for i, ax in enumerate(graficoPair.axes[:, 0]):
    ax.set_ylabel(nombres_columnas[i])

plt.show()

# Visualiación del grafico de dispersión con regresión enfocados en las variables largo y ancho del sépalo por especie
sns.lmplot(data=df_iris, x="sepal length (cm)", y="sepal width (cm)", hue="species_des",ci=98)
plt.xlabel("Sépalo (Largo)")
plt.ylabel("Sépalo (Ancho)")
plt.show()

plt.figure(figsize=(8,6))
graficoCorr = sns.heatmap(df_iris.select_dtypes(include="float64").corr(), annot=True, cmap="viridis", fmt=".2f")

graficoCorr.set_xticklabels(nombres_columnas, rotation=90)
graficoCorr.set_yticklabels(nombres_columnas, rotation=0)

plt.title("Matriz de Correlación")
plt.show()

"""# **V. Selección y Entrenamiento del Modelo**"""

# si esta ordenado, score sale = 1, score perfecto
df_iris = df_iris.sample(frac=1, random_state=42).reset_index(drop=True)

# División de la data de entrenamiento y testo
X = df_iris.select_dtypes(include="float64").values
Y = df_iris['species']

# Dividir los datos en conjuntos de entrenamiento y testeo
X_train, X_test, Y_train, Y_test =  train_test_split(X,Y,test_size=0.2, random_state=42)

# Crear y entrenar el modelo de Regresion Logística
model = LogisticRegression(max_iter=200)
model.fit(X_train, Y_train)

Y_pred = model.predict(X_test)

X_0 = X_test[0].reshape(-1,4)

Y_test.head(1)

Y_0 = model.predict(X_0)
Y_0[0]

"""#**VI. Evaluación del Modelo**"""

accuracy = accuracy_score(Y_test, Y_pred)
accuracy

score = model.score(X_test,Y_test)
score

cm = confusion_matrix(Y_test, Y_pred)

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicción")
plt.ylabel("Valor Real")
plt.title("Matriz de Confusión")
plt.show()

train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

train_mse = mean_squared_error(Y_train,train_predict)
test_mse = mean_squared_error(Y_test,test_predict)

print("Error de predicción en datos de entrenamiento MSE", train_mse)
print("Error de predicción en datos de testeo MSE", test_mse)

Y_predict_total = model.predict(X)

#Comparativa de las especies reales vs las espcies predichas totales
plt.figure(figsize=(10, 5))

plt.plot(df_iris.index, df_iris["species"], color="blue", label="Real")
plt.plot(df_iris.index, Y_predict_total, color="red", linestyle="dashed", label="Predicción")

plt.xlabel("Índice")
plt.ylabel("Especie")
plt.title("Comparación de Especies Reales vs. Predichas")
plt.legend()
plt.show()

"""#**VII. Ajuste y Optimización del Modelo:**"""

# Realizamos la validación cruzada en el modelo
scores = cross_val_score(model,X_train,Y_train,cv=5)

# Calculamos el promedio de los puntajes de validación cruzada
mean_score = np.mean(scores)
print("Promedio de validación cruzada",mean_score)

"""#**Elección del mejor modelo - Kfold cross validation**"""

seed = 42
folds = 10
metric= "neg_mean_squared_error"

model_results= list()
model_names=list()

models = {
    "Regresion Logistica": LogisticRegression(max_iter=200),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "SVM (RBF Kernel)": SVC(kernel="rbf"),
    "SVM (Linear Kernel)": SVC(kernel="linear"),
    "XGBoost": XGBClassifier(eval_metric="mlogloss"),
    "MLP (Neural Network)": MLPClassifier(hidden_layer_sizes=(10,), max_iter=2000)
}

for model_name in models:
  model= models[model_name]
  k_fold = KFold(n_splits=folds,random_state=seed,shuffle=True)
  results= cross_val_score(model,X_train,Y_train,cv=folds,scoring=metric)
  model_results.append(results)
  model_names.append(model_name)

  print("{:>20}: {:.2f},{:.2f}".format(model_name,round(results.mean(),3),round(results.std(),3)))

"""Se observa que el modelo de **regresión Logistica**, tiene un valor -0.004, lo que esta dentro de los modeles con mejor resultado para la predicción"""

import pickle
pickle.dump(model,open("ModeloRegresionLogistico_Iris.md","wb"))